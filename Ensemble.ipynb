{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, GRU \n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, Adagrad\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# sklearn\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# other\n",
    "# import tqdm notebook\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "#### Matplotlib settings\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "\n",
    "# specify default rcParams so that fontsize, weight and style don't need to be set each time\n",
    "# Title in bold, fontsize 20\n",
    "mpl.rcParams['figure.titleweight'] = 'bold'\n",
    "mpl.rcParams['figure.titlesize'] = 20\n",
    "mpl.rcParams['axes.titleweight'] = 'bold'\n",
    "mpl.rcParams['axes.titlesize'] = 20\n",
    "# Plot fontsize 16 and bold\n",
    "mpl.rcParams['axes.labelweight'] = 'bold'\n",
    "mpl.rcParams['axes.labelsize'] = 16\n",
    "# set figure size\n",
    "mpl.rcParams['figure.figsize'] = (18, 8)\n",
    "# set grid on\n",
    "mpl.rcParams['axes.grid'] = True\n",
    "# set grid linestyle\n",
    "mpl.rcParams['grid.linestyle'] = '--'\n",
    "# set axis labels fontsize\n",
    "mpl.rcParams['xtick.labelsize'] = 14\n",
    "mpl.rcParams['ytick.labelsize'] = 14\n",
    "\n",
    "# race list and colors that will be used to represent them\n",
    "RACE_LIST = [\n",
    "    'Protoss',\n",
    "    'Terran',\n",
    "    'Zerg'\n",
    "    ]\n",
    "COLOR_DICT = {\n",
    "    'Protoss': 'goldenrod',\n",
    "    'Terran': 'firebrick',\n",
    "    'Zerg': 'darkviolet'\n",
    "    }\n",
    "\n",
    "#### Pandas options\n",
    "# these are set to allow better exploration of the large dataframes in this \n",
    "# notebook\n",
    "pd.options.display.max_rows = 200\n",
    "pd.options.display.max_columns = 200\n",
    "\n",
    "#IPython\n",
    "from IPython.display import display\n",
    "%load_ext autoreload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator(keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        list_filehashes, \n",
    "        labels,\n",
    "        data_dir,\n",
    "        window_size,\n",
    "        n_channels,\n",
    "        window_start=0,\n",
    "        batch_size=32,  \n",
    "        n_classes=2, \n",
    "        shuffle=True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Generate batches of data for training.\n",
    "    \n",
    "        Args:\n",
    "            data (str): the path to a directory of npy files\n",
    "            labels (dict): a dictionary of filehashes and their corresponding labels\n",
    "            list_filehashes (list): the list of filehashes to use\n",
    "            window_size (int): the number of timesteps to use as a window\n",
    "            n_channels (int): the number of features in the data\n",
    "            batch_size (int): the number of samples per batch. Defaults to 32.\n",
    "            n_classes (int): the number of classes for the target. Defaults to 2.\n",
    "            shuffle (bool): whether to shuffle the data. Defaults to True.\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.window_size = window_size\n",
    "        self.window_start = window_start\n",
    "        self.n_channels = n_channels\n",
    "        self.list_IDs = list_filehashes\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' \n",
    "        # X : (n_samples, window_size, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, self.window_size, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "\n",
    "            # get X_tmp and then cut down to the window size\n",
    "            X_tmp = np.load(os.path.join(self.data_dir, ID + '.npy'))\n",
    "\n",
    "            X[i,] = X_tmp[\n",
    "                self.window_start:self.window_start + self.window_size,\n",
    "                :\n",
    "            ]\n",
    "\n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_data_for_modeling(\n",
    "    metadata_path='data/spawningtool_replays.csv',\n",
    "    master_columns_path='info/clean_master_columns_list.csv',\n",
    "    non_feature_columns=['winner', 'filehash', 'frame'],\n",
    "    partition_index=None,\n",
    "    window_size=60,\n",
    "    window_start=0,\n",
    "    verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Setup the data for modeling.\n",
    "    \n",
    "    Args:\n",
    "        metadata_path (str): the path to the metadata csv. Defaults to 'data/spawningtool_replays.csv'.\n",
    "        master_columns_path (str): the path to the master_columns_list csv. Defaults to 'info/clean_master_columns_list.csv'.\n",
    "        non_feature_columns (list): the list of non-feature columns. Defaults to ['winner', 'filehash', 'frame'].\n",
    "        window_size (int): the window size to use. Defaults to 60.\n",
    "        verbose (bool): whether to print out the progress. Defaults to True.\n",
    "\n",
    "    Returns tuple:\n",
    "        panda.DataFrame: the dataframe containing the metadata\n",
    "        list: the list of all columns\n",
    "        list: the list of feature columns\n",
    "        dict: the dictionary of train, val, and test filehashes\n",
    "        dict: the dictionary of labels\n",
    "    \"\"\"\n",
    "    # get spawningtool_df\n",
    "    spawningtool_df = pd.read_csv(metadata_path)\n",
    "\n",
    "    # get master_columns_list\n",
    "    master_columns_list = pd.read_csv(master_columns_path).values.tolist()\n",
    "    master_columns_list = [col[0] for col in master_columns_list]\n",
    "\n",
    "    # create non_feature_columns\n",
    "    non_feature_columns = ['winner', 'filehash', 'frame']\n",
    "    # create feature_columns list\n",
    "    feature_columns = [\n",
    "        col for col in master_columns_list if col not in non_feature_columns\n",
    "    ]\n",
    "\n",
    "    partition = {}\n",
    "\n",
    "    if partition_index is None:\n",
    "        # loop through files in the partitions and create a list of hashes that meet \n",
    "        # the window size\n",
    "        \n",
    "        for folder in ['train', 'val', 'test']:\n",
    "            # get the filenames in the folder\n",
    "            filehashes = [\n",
    "                os.path.splitext(f)[0] for f in os.listdir(\n",
    "                    f'data/model_data/{folder}'\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            partition_list = []\n",
    "            # load the file and check its shape[0]\n",
    "            for filehash in filehashes:\n",
    "                arr = np.load(f'data/model_data/{folder}/{filehash}.npy')\n",
    "                if arr.shape[0] > (window_size + window_start):\n",
    "                    partition_list.append(filehash)\n",
    "\n",
    "            # add the filehashes to the partition\n",
    "            partition[folder] = partition_list\n",
    "\n",
    "            # calculate number of files removed\n",
    "            removed = len(filehashes) - len(partition_list)\n",
    "\n",
    "            if verbose:\n",
    "                print(f'\\t{folder} has {len(filehashes)} valid files, removed {removed} files ({round(100*removed/len(filehashes),2)}%)')\n",
    "\n",
    "    else:\n",
    "        for folder in partition_index['partition'].unique():\n",
    "            # filter by shape > window_size + window_start\n",
    "            mask = (partition_index['partition'] == folder) \\\n",
    "                & (partition_index['shape'] > (window_size + window_start)) \n",
    "\n",
    "            # get the filehashes\n",
    "            partition[folder] = partition_index.loc[mask].index.values.tolist()\n",
    "\n",
    "\n",
    "    # construct the labels dictionary\n",
    "    labels = spawningtool_df[['game_winner', 'filehash']].set_index('filehash').to_dict()['game_winner']\n",
    "    # drop all keys with value == 0\n",
    "    labels = {k: v for k, v in labels.items() if v != 0}\n",
    "    # convert value all keys with value == 2 to 1\n",
    "    labels = {k: 0 if v == 2 else 1 for k, v in labels.items()}\n",
    "\n",
    "    return spawningtool_df, master_columns_list, feature_columns, partition, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create, train, evaluate, and save a model for a given window size\n",
    "def train_evaluate_model(\n",
    "    window_size,\n",
    "    partition_index,\n",
    "    window_start=0,  \n",
    "    save_models=True,\n",
    "    verbose=1\n",
    "):\n",
    "    \"\"\"\n",
    "    train_evaluate_model\n",
    "    Train, evaluate, and save a model for a given window size.\n",
    "\n",
    "    Args:\n",
    "        window_size (int): the window size to use\n",
    "        window_start (int): the window start to use. Defaults to 0.\n",
    "        save_models (bool): whether to save the models to file or not\n",
    "        verbose (int): the verbosity level for Keras. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        tuple: model, history, model_file, score, prediction_results\n",
    "    \"\"\"\n",
    "\n",
    "    print('\\tSetting up model data...')\n",
    "    # setup the model\n",
    "    # set up the data for modeling\n",
    "    _, _, feature_columns, partition, labels = setup_data_for_modeling(\n",
    "        window_size=window_size, \n",
    "        window_start=window_start,\n",
    "        partition_index=partition_index,\n",
    "    )\n",
    "\n",
    "    # create a dictionary of parameters to pass to both generators\n",
    "    params = {\n",
    "        'window_size': window_size, \n",
    "        'window_start': window_start,\n",
    "        'n_channels': len(feature_columns),\n",
    "        'batch_size': 32, \n",
    "        'shuffle': True\n",
    "    }\n",
    "\n",
    "    # setup generators for training and validation\n",
    "    training_generator = BatchGenerator(\n",
    "        partition['train'],\n",
    "        labels,\n",
    "        data_dir='data/model_data/train',\n",
    "        **params\n",
    "    )\n",
    "\n",
    "    validation_generator = BatchGenerator(\n",
    "        partition['val'],\n",
    "        labels,\n",
    "        data_dir='data/model_data/val',\n",
    "        **params\n",
    "    )\n",
    "\n",
    "    print('\\tCreating model architecture...')\n",
    "    # instantiate RNN model\n",
    "    model = Sequential()\n",
    "\n",
    "    # add LSTM layer\n",
    "    model.add(LSTM(\n",
    "        units=128,\n",
    "        input_shape=(window_size, len(feature_columns)),\n",
    "        return_sequences=False\n",
    "    ))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # add dense layer\n",
    "    model.add(Dense(\n",
    "        1, \n",
    "        activation='sigmoid', \n",
    "        kernel_regularizer=keras.regularizers.l1(0.01)\n",
    "    ))\n",
    "\n",
    "    # compile model using binary crossentropy loss and adam optimizer\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # generate a unique identifier for the model use LSTM nodes and window_size\n",
    "    model_file = f'models/lstm_size.{window_size}_from.{window_start}'\n",
    "    model_file_ext = '.h5'\n",
    "    # check if the model file exists and if so, append a version number\n",
    "    if os.path.exists(model_file+model_file_ext):\n",
    "        # iterate through the version number to find the next available version number\n",
    "        i = 1\n",
    "        model_file = model_file.split('_v')[0] + '_v' + str(i)\n",
    "        while os.path.exists(model_file+model_file_ext):\n",
    "            i += 1\n",
    "            model_file = model_file + '_v' + str(i)\n",
    "\n",
    "    # create a callback to log history\n",
    "    csv_logger = CSVLogger(model_file+'.csv')\n",
    "\n",
    "    # create a callback to save checkpoints\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath='models/checkpoints/'+model_file.split('/')[1]+'.hdf5',\n",
    "        monitor='val_loss',\n",
    "        verbose=0,\n",
    "        save_best_only=False\n",
    "    )\n",
    "\n",
    "    # create a callback which stops training when no improvement is being made\n",
    "    earlystop = EarlyStopping(\n",
    "        monitor='val_loss', # monitor validation loss to prevent overfitting\n",
    "        patience=2, # stop after 3 epochs without improvement\n",
    "        verbose=1,  # print a message when the callback is triggered\n",
    "        mode='auto' # keras infers if the monitored variable should be increasing or decreasing\n",
    "    )\n",
    "\n",
    "    # set up callbacks to be used for training\n",
    "    if save_models:\n",
    "        callbacks = [earlystop, csv_logger, checkpoint]\n",
    "    else:\n",
    "        callbacks = [earlystop]\n",
    "\n",
    "    print('\\tTraining model...')\n",
    "    # fit the model and save to history\n",
    "    history = model.fit(\n",
    "        training_generator,\n",
    "        validation_data=validation_generator,\n",
    "        epochs=50,\n",
    "        callbacks=callbacks,\n",
    "        verbose=verbose\n",
    "    )\n",
    "\n",
    "    if save_models:   \n",
    "        # pickle the model\n",
    "        model.save(model_file+model_file_ext)\n",
    "\n",
    "    # get the last value for val_accuracy\n",
    "    score = history.history['val_accuracy'][-1]\n",
    "\n",
    "    print('\\tGenerating predictions...')\n",
    "    # create a generator for predictions\n",
    "    prediction_generator = BatchGenerator(\n",
    "        partition['val'],\n",
    "        labels,\n",
    "        data_dir='data/model_data/val',\n",
    "        window_size=window_size,\n",
    "        window_start=window_start, \n",
    "        n_channels=len(feature_columns),\n",
    "        batch_size=1, \n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # make predictions\n",
    "    predictions = model.predict(prediction_generator)\n",
    "\n",
    "    # get the true labels for the predictions\n",
    "    true_labels = [labels[k] for k in partition['val']]\n",
    "\n",
    "    # create the prediction_results dataframe\n",
    "    prediction_results = pd.DataFrame({\n",
    "        'filehash': partition['val'],\n",
    "        'probability': predictions.reshape(-1),\n",
    "    })\n",
    "\n",
    "    # set the filehash as the index\n",
    "    prediction_results.set_index('filehash', inplace=True)\n",
    "\n",
    "    # return the model and the score\n",
    "    return model, history, model_file, score, prediction_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_partitions():\n",
    "    \n",
    "    folder_list = [\n",
    "        'data/model_data/train',\n",
    "        'data/model_data/val',\n",
    "        'data/model_data/test'\n",
    "    ]\n",
    "\n",
    "    partition_index = pd.DataFrame(columns=['filehash', 'shape'])\n",
    "\n",
    "    for folder in folder_list:\n",
    "        for file in os.listdir(folder):\n",
    "            filehash = os.path.splitext(file)[0]\n",
    "            partition_index = partition_index.append(\n",
    "                {\n",
    "                    'filehash': filehash,\n",
    "                    'shape': int(\n",
    "                        np.load(folder+'/'+file, mmap_mode='r').shape[0]),\n",
    "                    'partition': folder.split('/')[-1]\n",
    "                },\n",
    "                ignore_index=True\n",
    "            )\n",
    "\n",
    "    partition_index.set_index('filehash', inplace=True)\n",
    "\n",
    "    print('Partitioning complete.')\n",
    "\n",
    "    return partition_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitioning data...\n",
      "Partitioning complete.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e4405d16fe241c0a41a4e19c11ae601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training models:   0%|          | 0/247 [00:00<?, ?model/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00009: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00007: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00008: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00009: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00008: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00006: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00008: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00007: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00008: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00008: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00005: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00007: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00008: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00008: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00008: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00006: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00007: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00007: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00007: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00005: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00007: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00004: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00006: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00005: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00005: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00006: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00006: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00005: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00005: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00004: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00006: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00006: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00004: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00005: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00005: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00004: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00005: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00004: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00009: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n",
      "Epoch 00007: early stopping\n",
      "\tGenerating predictions...\n",
      "Done!\n",
      "--------------------------------------------------------------------------------\n",
      "\tSetting up model data...\n",
      "\tCreating model architecture...\n",
      "\tTraining model...\n"
     ]
    }
   ],
   "source": [
    "model_dict = {}\n",
    "i = 0\n",
    "print('Partitioning data...')\n",
    "partition_index = create_partitions()\n",
    "print('-'*80)\n",
    "\n",
    "# create a list of window sizes and start tuples\n",
    "model_params = []\n",
    "for window_size in np.arange(48, 121, 6):\n",
    "    for window_start in np.arange(0, 121 - window_size, step=2):\n",
    "        model_params.append((window_size, window_start))\n",
    "\n",
    "for i in tqdm(range(len(model_params)), \n",
    "    desc='Training models',\n",
    "    unit='model'\n",
    "):\n",
    "    # get the window size and start tuple\n",
    "    window_size, window_start = model_params[i]\n",
    "\n",
    "    # set up the model\n",
    "    model, history, model_file, score, new_pred_results = train_evaluate_model(\n",
    "        window_size=window_size,\n",
    "        window_start=window_start,\n",
    "        save_models=False,\n",
    "        partition_index=partition_index,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    model_index = str(window_start)+'_'+str(window_size)\n",
    "\n",
    "    new_pred_results.rename(\n",
    "        columns={'probability': model_index},\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    if i == 0:\n",
    "        prediction_results = new_pred_results\n",
    "    else:\n",
    "        prediction_results = pd.concat(\n",
    "            [prediction_results, new_pred_results], \n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "    # save models in a dict keyed by window_start + window_size\n",
    "    model_dict[model_index] = model\n",
    "    print('Done!')\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_12</th>\n",
       "      <th>10_12</th>\n",
       "      <th>20_12</th>\n",
       "      <th>30_12</th>\n",
       "      <th>40_12</th>\n",
       "      <th>50_12</th>\n",
       "      <th>60_12</th>\n",
       "      <th>70_12</th>\n",
       "      <th>80_12</th>\n",
       "      <th>90_12</th>\n",
       "      <th>100_12</th>\n",
       "      <th>0_24</th>\n",
       "      <th>10_24</th>\n",
       "      <th>20_24</th>\n",
       "      <th>30_24</th>\n",
       "      <th>40_24</th>\n",
       "      <th>50_24</th>\n",
       "      <th>60_24</th>\n",
       "      <th>70_24</th>\n",
       "      <th>80_24</th>\n",
       "      <th>90_24</th>\n",
       "      <th>0_36</th>\n",
       "      <th>10_36</th>\n",
       "      <th>20_36</th>\n",
       "      <th>30_36</th>\n",
       "      <th>40_36</th>\n",
       "      <th>50_36</th>\n",
       "      <th>60_36</th>\n",
       "      <th>70_36</th>\n",
       "      <th>80_36</th>\n",
       "      <th>0_48</th>\n",
       "      <th>10_48</th>\n",
       "      <th>20_48</th>\n",
       "      <th>30_48</th>\n",
       "      <th>40_48</th>\n",
       "      <th>50_48</th>\n",
       "      <th>60_48</th>\n",
       "      <th>70_48</th>\n",
       "      <th>0_60</th>\n",
       "      <th>10_60</th>\n",
       "      <th>20_60</th>\n",
       "      <th>30_60</th>\n",
       "      <th>40_60</th>\n",
       "      <th>50_60</th>\n",
       "      <th>60_60</th>\n",
       "      <th>0_72</th>\n",
       "      <th>10_72</th>\n",
       "      <th>20_72</th>\n",
       "      <th>30_72</th>\n",
       "      <th>40_72</th>\n",
       "      <th>0_84</th>\n",
       "      <th>10_84</th>\n",
       "      <th>20_84</th>\n",
       "      <th>30_84</th>\n",
       "      <th>0_96</th>\n",
       "      <th>10_96</th>\n",
       "      <th>20_96</th>\n",
       "      <th>0_108</th>\n",
       "      <th>10_108</th>\n",
       "      <th>0_120</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filehash</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0016ddd5b36473f259ba8630c6c0047540a6858071737e8f890358d3f7ad355d</th>\n",
       "      <td>0.478540</td>\n",
       "      <td>0.598060</td>\n",
       "      <td>0.087926</td>\n",
       "      <td>0.199271</td>\n",
       "      <td>0.124007</td>\n",
       "      <td>0.135398</td>\n",
       "      <td>0.039492</td>\n",
       "      <td>0.065046</td>\n",
       "      <td>0.489937</td>\n",
       "      <td>0.084131</td>\n",
       "      <td>0.104387</td>\n",
       "      <td>0.066167</td>\n",
       "      <td>0.067840</td>\n",
       "      <td>0.309149</td>\n",
       "      <td>0.095017</td>\n",
       "      <td>0.213251</td>\n",
       "      <td>0.220668</td>\n",
       "      <td>0.177882</td>\n",
       "      <td>0.495852</td>\n",
       "      <td>0.344256</td>\n",
       "      <td>0.098148</td>\n",
       "      <td>0.161989</td>\n",
       "      <td>0.092753</td>\n",
       "      <td>0.123710</td>\n",
       "      <td>0.028176</td>\n",
       "      <td>0.020097</td>\n",
       "      <td>0.387979</td>\n",
       "      <td>0.849240</td>\n",
       "      <td>0.537468</td>\n",
       "      <td>0.795417</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>0.046480</td>\n",
       "      <td>0.034467</td>\n",
       "      <td>0.026782</td>\n",
       "      <td>0.212772</td>\n",
       "      <td>0.808688</td>\n",
       "      <td>0.414511</td>\n",
       "      <td>0.232392</td>\n",
       "      <td>0.131178</td>\n",
       "      <td>0.026408</td>\n",
       "      <td>0.010254</td>\n",
       "      <td>0.072036</td>\n",
       "      <td>0.086759</td>\n",
       "      <td>0.710828</td>\n",
       "      <td>0.079258</td>\n",
       "      <td>0.085336</td>\n",
       "      <td>0.015620</td>\n",
       "      <td>0.624395</td>\n",
       "      <td>0.051603</td>\n",
       "      <td>0.167276</td>\n",
       "      <td>0.014730</td>\n",
       "      <td>0.283410</td>\n",
       "      <td>0.465344</td>\n",
       "      <td>0.327579</td>\n",
       "      <td>0.787177</td>\n",
       "      <td>0.606639</td>\n",
       "      <td>0.486119</td>\n",
       "      <td>0.212930</td>\n",
       "      <td>0.072556</td>\n",
       "      <td>0.324719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e7827e10660ad88bf5bee</th>\n",
       "      <td>0.526600</td>\n",
       "      <td>0.614885</td>\n",
       "      <td>0.258713</td>\n",
       "      <td>0.389767</td>\n",
       "      <td>0.789966</td>\n",
       "      <td>0.724467</td>\n",
       "      <td>0.571540</td>\n",
       "      <td>0.967763</td>\n",
       "      <td>0.291989</td>\n",
       "      <td>0.021289</td>\n",
       "      <td>0.516867</td>\n",
       "      <td>0.296109</td>\n",
       "      <td>0.244836</td>\n",
       "      <td>0.860500</td>\n",
       "      <td>0.715670</td>\n",
       "      <td>0.924575</td>\n",
       "      <td>0.968490</td>\n",
       "      <td>0.837172</td>\n",
       "      <td>0.925201</td>\n",
       "      <td>0.760122</td>\n",
       "      <td>0.143616</td>\n",
       "      <td>0.324150</td>\n",
       "      <td>0.353952</td>\n",
       "      <td>0.732399</td>\n",
       "      <td>0.885020</td>\n",
       "      <td>0.956954</td>\n",
       "      <td>0.801989</td>\n",
       "      <td>0.299489</td>\n",
       "      <td>0.740694</td>\n",
       "      <td>0.036893</td>\n",
       "      <td>0.262166</td>\n",
       "      <td>0.711719</td>\n",
       "      <td>0.830663</td>\n",
       "      <td>0.362114</td>\n",
       "      <td>0.188171</td>\n",
       "      <td>0.626452</td>\n",
       "      <td>0.235078</td>\n",
       "      <td>0.297810</td>\n",
       "      <td>0.167221</td>\n",
       "      <td>0.863784</td>\n",
       "      <td>0.848653</td>\n",
       "      <td>0.303732</td>\n",
       "      <td>0.334280</td>\n",
       "      <td>0.126523</td>\n",
       "      <td>0.101359</td>\n",
       "      <td>0.934342</td>\n",
       "      <td>0.355163</td>\n",
       "      <td>0.614399</td>\n",
       "      <td>0.224636</td>\n",
       "      <td>0.394577</td>\n",
       "      <td>0.353212</td>\n",
       "      <td>0.681236</td>\n",
       "      <td>0.811928</td>\n",
       "      <td>0.052835</td>\n",
       "      <td>0.556868</td>\n",
       "      <td>0.720422</td>\n",
       "      <td>0.661394</td>\n",
       "      <td>0.278303</td>\n",
       "      <td>0.497171</td>\n",
       "      <td>0.457617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0033334e86cb352b0131027e58effa23adb23cf1cdd90d5760cc62254611c99a</th>\n",
       "      <td>0.563810</td>\n",
       "      <td>0.688602</td>\n",
       "      <td>0.520770</td>\n",
       "      <td>0.486146</td>\n",
       "      <td>0.877253</td>\n",
       "      <td>0.941794</td>\n",
       "      <td>0.877516</td>\n",
       "      <td>0.786566</td>\n",
       "      <td>0.953953</td>\n",
       "      <td>0.637254</td>\n",
       "      <td>0.724162</td>\n",
       "      <td>0.437219</td>\n",
       "      <td>0.511848</td>\n",
       "      <td>0.919635</td>\n",
       "      <td>0.956855</td>\n",
       "      <td>0.937908</td>\n",
       "      <td>0.929437</td>\n",
       "      <td>0.956660</td>\n",
       "      <td>0.902231</td>\n",
       "      <td>0.780797</td>\n",
       "      <td>0.661751</td>\n",
       "      <td>0.659244</td>\n",
       "      <td>0.602856</td>\n",
       "      <td>0.955341</td>\n",
       "      <td>0.967760</td>\n",
       "      <td>0.863017</td>\n",
       "      <td>0.404402</td>\n",
       "      <td>0.863395</td>\n",
       "      <td>0.908409</td>\n",
       "      <td>0.950806</td>\n",
       "      <td>0.554702</td>\n",
       "      <td>0.874749</td>\n",
       "      <td>0.905928</td>\n",
       "      <td>0.887714</td>\n",
       "      <td>0.650530</td>\n",
       "      <td>0.737742</td>\n",
       "      <td>0.844959</td>\n",
       "      <td>0.749974</td>\n",
       "      <td>0.946754</td>\n",
       "      <td>0.871522</td>\n",
       "      <td>0.950233</td>\n",
       "      <td>0.811946</td>\n",
       "      <td>0.728694</td>\n",
       "      <td>0.591851</td>\n",
       "      <td>0.949278</td>\n",
       "      <td>0.954007</td>\n",
       "      <td>0.883900</td>\n",
       "      <td>0.921593</td>\n",
       "      <td>0.789151</td>\n",
       "      <td>0.504180</td>\n",
       "      <td>0.977398</td>\n",
       "      <td>0.904713</td>\n",
       "      <td>0.906649</td>\n",
       "      <td>0.683410</td>\n",
       "      <td>0.599961</td>\n",
       "      <td>0.896923</td>\n",
       "      <td>0.427648</td>\n",
       "      <td>0.809621</td>\n",
       "      <td>0.677286</td>\n",
       "      <td>0.933748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0055f4541fe30a72e964fc168db7abef35822d27e4cdce8ef0adb8b3cba51b7d</th>\n",
       "      <td>0.654678</td>\n",
       "      <td>0.666470</td>\n",
       "      <td>0.549546</td>\n",
       "      <td>0.752763</td>\n",
       "      <td>0.882442</td>\n",
       "      <td>0.946826</td>\n",
       "      <td>0.874497</td>\n",
       "      <td>0.994796</td>\n",
       "      <td>0.953706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.551776</td>\n",
       "      <td>0.796762</td>\n",
       "      <td>0.971220</td>\n",
       "      <td>0.978145</td>\n",
       "      <td>0.943856</td>\n",
       "      <td>0.980214</td>\n",
       "      <td>0.984904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.727291</td>\n",
       "      <td>0.788836</td>\n",
       "      <td>0.980208</td>\n",
       "      <td>0.947675</td>\n",
       "      <td>0.978365</td>\n",
       "      <td>0.977469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.756230</td>\n",
       "      <td>0.977553</td>\n",
       "      <td>0.957861</td>\n",
       "      <td>0.986316</td>\n",
       "      <td>0.997820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.982317</td>\n",
       "      <td>0.947037</td>\n",
       "      <td>0.984399</td>\n",
       "      <td>0.983914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.845061</td>\n",
       "      <td>0.979166</td>\n",
       "      <td>0.969678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.977412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e46cd9f2cbf3fa3a99</th>\n",
       "      <td>0.410807</td>\n",
       "      <td>0.697154</td>\n",
       "      <td>0.425629</td>\n",
       "      <td>0.818765</td>\n",
       "      <td>0.884527</td>\n",
       "      <td>0.958854</td>\n",
       "      <td>0.884232</td>\n",
       "      <td>0.905400</td>\n",
       "      <td>0.998261</td>\n",
       "      <td>0.838431</td>\n",
       "      <td>0.978269</td>\n",
       "      <td>0.627104</td>\n",
       "      <td>0.574905</td>\n",
       "      <td>0.970679</td>\n",
       "      <td>0.956108</td>\n",
       "      <td>0.988558</td>\n",
       "      <td>0.992553</td>\n",
       "      <td>0.952348</td>\n",
       "      <td>0.977642</td>\n",
       "      <td>0.973903</td>\n",
       "      <td>0.959005</td>\n",
       "      <td>0.544934</td>\n",
       "      <td>0.708364</td>\n",
       "      <td>0.982398</td>\n",
       "      <td>0.954283</td>\n",
       "      <td>0.988978</td>\n",
       "      <td>0.983640</td>\n",
       "      <td>0.979953</td>\n",
       "      <td>0.921636</td>\n",
       "      <td>0.992276</td>\n",
       "      <td>0.841827</td>\n",
       "      <td>0.974754</td>\n",
       "      <td>0.937327</td>\n",
       "      <td>0.705655</td>\n",
       "      <td>0.937284</td>\n",
       "      <td>0.987146</td>\n",
       "      <td>0.986139</td>\n",
       "      <td>0.971984</td>\n",
       "      <td>0.945515</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.989564</td>\n",
       "      <td>0.925274</td>\n",
       "      <td>0.945632</td>\n",
       "      <td>0.973543</td>\n",
       "      <td>0.995174</td>\n",
       "      <td>0.952927</td>\n",
       "      <td>0.951038</td>\n",
       "      <td>0.999048</td>\n",
       "      <td>0.948825</td>\n",
       "      <td>0.985612</td>\n",
       "      <td>0.987062</td>\n",
       "      <td>0.976674</td>\n",
       "      <td>0.932410</td>\n",
       "      <td>0.958789</td>\n",
       "      <td>0.979521</td>\n",
       "      <td>0.924713</td>\n",
       "      <td>0.977090</td>\n",
       "      <td>0.916390</td>\n",
       "      <td>0.958075</td>\n",
       "      <td>0.997279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0_12     10_12  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.478540  0.598060   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.526600  0.614885   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.563810  0.688602   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.654678  0.666470   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.410807  0.697154   \n",
       "\n",
       "                                                       20_12     30_12  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.087926  0.199271   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.258713  0.389767   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.520770  0.486146   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.549546  0.752763   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.425629  0.818765   \n",
       "\n",
       "                                                       40_12     50_12  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.124007  0.135398   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.789966  0.724467   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.877253  0.941794   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.882442  0.946826   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.884527  0.958854   \n",
       "\n",
       "                                                       60_12     70_12  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.039492  0.065046   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.571540  0.967763   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.877516  0.786566   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.874497  0.994796   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.884232  0.905400   \n",
       "\n",
       "                                                       80_12     90_12  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.489937  0.084131   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.291989  0.021289   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.953953  0.637254   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.953706       NaN   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.998261  0.838431   \n",
       "\n",
       "                                                      100_12      0_24  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.104387  0.066167   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.516867  0.296109   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.724162  0.437219   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...       NaN  0.551776   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.978269  0.627104   \n",
       "\n",
       "                                                       10_24     20_24  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.067840  0.309149   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.244836  0.860500   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.511848  0.919635   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.796762  0.971220   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.574905  0.970679   \n",
       "\n",
       "                                                       30_24     40_24  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.095017  0.213251   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.715670  0.924575   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.956855  0.937908   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.978145  0.943856   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.956108  0.988558   \n",
       "\n",
       "                                                       50_24     60_24  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.220668  0.177882   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.968490  0.837172   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.929437  0.956660   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.980214  0.984904   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.992553  0.952348   \n",
       "\n",
       "                                                       70_24     80_24  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.495852  0.344256   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.925201  0.760122   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.902231  0.780797   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...       NaN       NaN   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.977642  0.973903   \n",
       "\n",
       "                                                       90_24      0_36  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.098148  0.161989   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.143616  0.324150   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.661751  0.659244   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...       NaN  0.727291   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.959005  0.544934   \n",
       "\n",
       "                                                       10_36     20_36  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.092753  0.123710   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.353952  0.732399   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.602856  0.955341   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.788836  0.980208   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.708364  0.982398   \n",
       "\n",
       "                                                       30_36     40_36  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.028176  0.020097   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.885020  0.956954   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.967760  0.863017   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.947675  0.978365   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.954283  0.988978   \n",
       "\n",
       "                                                       50_36     60_36  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.387979  0.849240   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.801989  0.299489   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.404402  0.863395   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.977469       NaN   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.983640  0.979953   \n",
       "\n",
       "                                                       70_36     80_36  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.537468  0.795417   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.740694  0.036893   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.908409  0.950806   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...       NaN       NaN   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.921636  0.992276   \n",
       "\n",
       "                                                        0_48     10_48  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.019592  0.046480   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.262166  0.711719   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.554702  0.874749   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.756230  0.977553   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.841827  0.974754   \n",
       "\n",
       "                                                       20_48     30_48  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.034467  0.026782   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.830663  0.362114   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.905928  0.887714   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.957861  0.986316   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.937327  0.705655   \n",
       "\n",
       "                                                       40_48     50_48  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.212772  0.808688   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.188171  0.626452   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.650530  0.737742   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.997820       NaN   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.937284  0.987146   \n",
       "\n",
       "                                                       60_48     70_48  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.414511  0.232392   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.235078  0.297810   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.844959  0.749974   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...       NaN       NaN   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.986139  0.971984   \n",
       "\n",
       "                                                        0_60     10_60  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.131178  0.026408   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.167221  0.863784   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.946754  0.871522   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.982317  0.947037   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.945515  0.977011   \n",
       "\n",
       "                                                       20_60     30_60  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.010254  0.072036   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.848653  0.303732   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.950233  0.811946   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.984399  0.983914   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.989564  0.925274   \n",
       "\n",
       "                                                       40_60     50_60  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.086759  0.710828   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.334280  0.126523   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.728694  0.591851   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...       NaN       NaN   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.945632  0.973543   \n",
       "\n",
       "                                                       60_60      0_72  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.079258  0.085336   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.101359  0.934342   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.949278  0.954007   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...       NaN  0.845061   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.995174  0.952927   \n",
       "\n",
       "                                                       10_72     20_72  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.015620  0.624395   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.355163  0.614399   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.883900  0.921593   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.979166  0.969678   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.951038  0.999048   \n",
       "\n",
       "                                                       30_72     40_72  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.051603  0.167276   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.224636  0.394577   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.789151  0.504180   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...       NaN       NaN   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.948825  0.985612   \n",
       "\n",
       "                                                        0_84     10_84  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.014730  0.283410   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.353212  0.681236   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.977398  0.904713   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.977412       NaN   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.987062  0.976674   \n",
       "\n",
       "                                                       20_84     30_84  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.465344  0.327579   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.811928  0.052835   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.906649  0.683410   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...       NaN       NaN   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.932410  0.958789   \n",
       "\n",
       "                                                        0_96     10_96  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.787177  0.606639   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.556868  0.720422   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.599961  0.896923   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...       NaN       NaN   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.979521  0.924713   \n",
       "\n",
       "                                                       20_96     0_108  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.486119  0.212930   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.661394  0.278303   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.427648  0.809621   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...       NaN       NaN   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.977090  0.916390   \n",
       "\n",
       "                                                      10_108     0_120  \n",
       "filehash                                                                \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.072556  0.324719  \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.497171  0.457617  \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.677286  0.933748  \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...       NaN       NaN  \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.958075  0.997279  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through each col in prediction results and get a dict of index to sum\n",
    "prob_index_dict = {}\n",
    "for col in prediction_results.columns:\n",
    "    # calculate the row at which the window ends\n",
    "    end_frame = int(col.split('_')[0]) + int(col.split('_')[1])\n",
    "    \n",
    "    # if the end frame is not in the dict, add it\n",
    "    if end_frame not in prob_index_dict.keys():\n",
    "        prob_index_dict[end_frame] = [col]\n",
    "    else:\n",
    "        prob_index_dict[end_frame].append(col)\n",
    "\n",
    "\n",
    "agg_predictions = pd.DataFrame()\n",
    "# loop through each key in the dict and get the mean of the values\n",
    "for filehash_i in prediction_results.index:\n",
    "    for end_frame in prob_index_dict.keys():\n",
    "        # calculate the mean of the values and add to the dataframe indexed by filehash_i\n",
    "        agg_prob = np.mean(\n",
    "            prediction_results.loc[\n",
    "                filehash_i,\n",
    "                prob_index_dict[end_frame]\n",
    "            ].values\n",
    "        )\n",
    "        agg_predictions = agg_predictions.append(\n",
    "            {\n",
    "                'filehash': filehash_i,\n",
    "                end_frame: agg_prob\n",
    "            },\n",
    "            ignore_index=True\n",
    "        )\n",
    "\n",
    "agg_predictions.set_index('filehash', inplace=True)\n",
    "agg_predictions.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "spawningtool_df = pd.read_csv('data/spawningtool_replays.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12</th>\n",
       "      <th>22</th>\n",
       "      <th>24</th>\n",
       "      <th>32</th>\n",
       "      <th>34</th>\n",
       "      <th>36</th>\n",
       "      <th>42</th>\n",
       "      <th>44</th>\n",
       "      <th>46</th>\n",
       "      <th>48</th>\n",
       "      <th>52</th>\n",
       "      <th>54</th>\n",
       "      <th>56</th>\n",
       "      <th>58</th>\n",
       "      <th>60</th>\n",
       "      <th>62</th>\n",
       "      <th>64</th>\n",
       "      <th>66</th>\n",
       "      <th>68</th>\n",
       "      <th>70</th>\n",
       "      <th>72</th>\n",
       "      <th>74</th>\n",
       "      <th>76</th>\n",
       "      <th>78</th>\n",
       "      <th>80</th>\n",
       "      <th>82</th>\n",
       "      <th>84</th>\n",
       "      <th>86</th>\n",
       "      <th>88</th>\n",
       "      <th>90</th>\n",
       "      <th>92</th>\n",
       "      <th>94</th>\n",
       "      <th>96</th>\n",
       "      <th>98</th>\n",
       "      <th>100</th>\n",
       "      <th>102</th>\n",
       "      <th>104</th>\n",
       "      <th>106</th>\n",
       "      <th>108</th>\n",
       "      <th>110</th>\n",
       "      <th>112</th>\n",
       "      <th>114</th>\n",
       "      <th>116</th>\n",
       "      <th>118</th>\n",
       "      <th>120</th>\n",
       "      <th>winner</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filehash</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0016ddd5b36473f259ba8630c6c0047540a6858071737e8f890358d3f7ad355d</th>\n",
       "      <td>0.478540</td>\n",
       "      <td>0.598060</td>\n",
       "      <td>0.066167</td>\n",
       "      <td>0.087926</td>\n",
       "      <td>0.067840</td>\n",
       "      <td>0.161989</td>\n",
       "      <td>0.199271</td>\n",
       "      <td>0.309149</td>\n",
       "      <td>0.092753</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>0.124007</td>\n",
       "      <td>0.095017</td>\n",
       "      <td>0.123710</td>\n",
       "      <td>0.046480</td>\n",
       "      <td>0.131178</td>\n",
       "      <td>0.135398</td>\n",
       "      <td>0.213251</td>\n",
       "      <td>0.028176</td>\n",
       "      <td>0.034467</td>\n",
       "      <td>0.026408</td>\n",
       "      <td>0.062414</td>\n",
       "      <td>0.220668</td>\n",
       "      <td>0.020097</td>\n",
       "      <td>0.026782</td>\n",
       "      <td>0.010254</td>\n",
       "      <td>0.040333</td>\n",
       "      <td>0.096306</td>\n",
       "      <td>0.387979</td>\n",
       "      <td>0.212772</td>\n",
       "      <td>0.072036</td>\n",
       "      <td>0.557166</td>\n",
       "      <td>0.389631</td>\n",
       "      <td>0.818208</td>\n",
       "      <td>0.808688</td>\n",
       "      <td>0.086759</td>\n",
       "      <td>0.067867</td>\n",
       "      <td>0.404800</td>\n",
       "      <td>0.572054</td>\n",
       "      <td>0.313721</td>\n",
       "      <td>0.710828</td>\n",
       "      <td>0.135832</td>\n",
       "      <td>0.212864</td>\n",
       "      <td>0.640768</td>\n",
       "      <td>0.152474</td>\n",
       "      <td>0.201989</td>\n",
       "      <td>0</td>\n",
       "      <td>161.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e7827e10660ad88bf5bee</th>\n",
       "      <td>0.526600</td>\n",
       "      <td>0.614885</td>\n",
       "      <td>0.296109</td>\n",
       "      <td>0.258713</td>\n",
       "      <td>0.244836</td>\n",
       "      <td>0.324150</td>\n",
       "      <td>0.389767</td>\n",
       "      <td>0.860500</td>\n",
       "      <td>0.353952</td>\n",
       "      <td>0.262166</td>\n",
       "      <td>0.789966</td>\n",
       "      <td>0.715670</td>\n",
       "      <td>0.732399</td>\n",
       "      <td>0.711719</td>\n",
       "      <td>0.167221</td>\n",
       "      <td>0.724467</td>\n",
       "      <td>0.924575</td>\n",
       "      <td>0.885020</td>\n",
       "      <td>0.830663</td>\n",
       "      <td>0.863784</td>\n",
       "      <td>0.752941</td>\n",
       "      <td>0.968490</td>\n",
       "      <td>0.956954</td>\n",
       "      <td>0.362114</td>\n",
       "      <td>0.848653</td>\n",
       "      <td>0.661463</td>\n",
       "      <td>0.595192</td>\n",
       "      <td>0.801989</td>\n",
       "      <td>0.188171</td>\n",
       "      <td>0.303732</td>\n",
       "      <td>0.453194</td>\n",
       "      <td>0.803219</td>\n",
       "      <td>0.428179</td>\n",
       "      <td>0.626452</td>\n",
       "      <td>0.334280</td>\n",
       "      <td>0.122963</td>\n",
       "      <td>0.786025</td>\n",
       "      <td>0.730558</td>\n",
       "      <td>0.256690</td>\n",
       "      <td>0.126523</td>\n",
       "      <td>0.455722</td>\n",
       "      <td>0.098226</td>\n",
       "      <td>0.349144</td>\n",
       "      <td>0.397491</td>\n",
       "      <td>0.279488</td>\n",
       "      <td>0</td>\n",
       "      <td>178.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0033334e86cb352b0131027e58effa23adb23cf1cdd90d5760cc62254611c99a</th>\n",
       "      <td>0.563810</td>\n",
       "      <td>0.688602</td>\n",
       "      <td>0.437219</td>\n",
       "      <td>0.520770</td>\n",
       "      <td>0.511848</td>\n",
       "      <td>0.659244</td>\n",
       "      <td>0.486146</td>\n",
       "      <td>0.919635</td>\n",
       "      <td>0.602856</td>\n",
       "      <td>0.554702</td>\n",
       "      <td>0.877253</td>\n",
       "      <td>0.956855</td>\n",
       "      <td>0.955341</td>\n",
       "      <td>0.874749</td>\n",
       "      <td>0.946754</td>\n",
       "      <td>0.941794</td>\n",
       "      <td>0.937908</td>\n",
       "      <td>0.967760</td>\n",
       "      <td>0.905928</td>\n",
       "      <td>0.871522</td>\n",
       "      <td>0.915761</td>\n",
       "      <td>0.929437</td>\n",
       "      <td>0.863017</td>\n",
       "      <td>0.887714</td>\n",
       "      <td>0.950233</td>\n",
       "      <td>0.835233</td>\n",
       "      <td>0.967029</td>\n",
       "      <td>0.404402</td>\n",
       "      <td>0.650530</td>\n",
       "      <td>0.811946</td>\n",
       "      <td>0.937773</td>\n",
       "      <td>0.903472</td>\n",
       "      <td>0.731678</td>\n",
       "      <td>0.737742</td>\n",
       "      <td>0.728694</td>\n",
       "      <td>0.713203</td>\n",
       "      <td>0.843723</td>\n",
       "      <td>0.902666</td>\n",
       "      <td>0.827290</td>\n",
       "      <td>0.591851</td>\n",
       "      <td>0.614171</td>\n",
       "      <td>0.672580</td>\n",
       "      <td>0.689227</td>\n",
       "      <td>0.713630</td>\n",
       "      <td>0.941513</td>\n",
       "      <td>1</td>\n",
       "      <td>214.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0055f4541fe30a72e964fc168db7abef35822d27e4cdce8ef0adb8b3cba51b7d</th>\n",
       "      <td>0.654678</td>\n",
       "      <td>0.666470</td>\n",
       "      <td>0.551776</td>\n",
       "      <td>0.549546</td>\n",
       "      <td>0.796762</td>\n",
       "      <td>0.727291</td>\n",
       "      <td>0.752763</td>\n",
       "      <td>0.971220</td>\n",
       "      <td>0.788836</td>\n",
       "      <td>0.756230</td>\n",
       "      <td>0.882442</td>\n",
       "      <td>0.978145</td>\n",
       "      <td>0.980208</td>\n",
       "      <td>0.977553</td>\n",
       "      <td>0.982317</td>\n",
       "      <td>0.946826</td>\n",
       "      <td>0.943856</td>\n",
       "      <td>0.947675</td>\n",
       "      <td>0.957861</td>\n",
       "      <td>0.947037</td>\n",
       "      <td>0.859779</td>\n",
       "      <td>0.980214</td>\n",
       "      <td>0.978365</td>\n",
       "      <td>0.986316</td>\n",
       "      <td>0.984399</td>\n",
       "      <td>0.986981</td>\n",
       "      <td>0.981158</td>\n",
       "      <td>0.977469</td>\n",
       "      <td>0.997820</td>\n",
       "      <td>0.983914</td>\n",
       "      <td>0.961692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>94.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e46cd9f2cbf3fa3a99</th>\n",
       "      <td>0.410807</td>\n",
       "      <td>0.697154</td>\n",
       "      <td>0.627104</td>\n",
       "      <td>0.425629</td>\n",
       "      <td>0.574905</td>\n",
       "      <td>0.544934</td>\n",
       "      <td>0.818765</td>\n",
       "      <td>0.970679</td>\n",
       "      <td>0.708364</td>\n",
       "      <td>0.841827</td>\n",
       "      <td>0.884527</td>\n",
       "      <td>0.956108</td>\n",
       "      <td>0.982398</td>\n",
       "      <td>0.974754</td>\n",
       "      <td>0.945515</td>\n",
       "      <td>0.958854</td>\n",
       "      <td>0.988558</td>\n",
       "      <td>0.954283</td>\n",
       "      <td>0.937327</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.918579</td>\n",
       "      <td>0.992553</td>\n",
       "      <td>0.988978</td>\n",
       "      <td>0.705655</td>\n",
       "      <td>0.989564</td>\n",
       "      <td>0.928219</td>\n",
       "      <td>0.969705</td>\n",
       "      <td>0.983640</td>\n",
       "      <td>0.937284</td>\n",
       "      <td>0.925274</td>\n",
       "      <td>0.998654</td>\n",
       "      <td>0.977158</td>\n",
       "      <td>0.979737</td>\n",
       "      <td>0.987146</td>\n",
       "      <td>0.945632</td>\n",
       "      <td>0.893628</td>\n",
       "      <td>0.953157</td>\n",
       "      <td>0.923174</td>\n",
       "      <td>0.951265</td>\n",
       "      <td>0.973543</td>\n",
       "      <td>0.981940</td>\n",
       "      <td>0.958897</td>\n",
       "      <td>0.984683</td>\n",
       "      <td>0.965030</td>\n",
       "      <td>0.996227</td>\n",
       "      <td>1</td>\n",
       "      <td>126.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>005e3a2f3a37e7afcc8050a73dfba1ef61394aa96202bbae4e521d69cdabdea5</th>\n",
       "      <td>0.405662</td>\n",
       "      <td>0.552058</td>\n",
       "      <td>0.256317</td>\n",
       "      <td>0.550325</td>\n",
       "      <td>0.355961</td>\n",
       "      <td>0.707999</td>\n",
       "      <td>0.559632</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>0.318067</td>\n",
       "      <td>0.184898</td>\n",
       "      <td>0.236122</td>\n",
       "      <td>0.281500</td>\n",
       "      <td>0.652278</td>\n",
       "      <td>0.447956</td>\n",
       "      <td>0.156842</td>\n",
       "      <td>0.614004</td>\n",
       "      <td>0.763232</td>\n",
       "      <td>0.949061</td>\n",
       "      <td>0.899879</td>\n",
       "      <td>0.820812</td>\n",
       "      <td>0.694565</td>\n",
       "      <td>0.339294</td>\n",
       "      <td>0.821932</td>\n",
       "      <td>0.950007</td>\n",
       "      <td>0.612075</td>\n",
       "      <td>0.877753</td>\n",
       "      <td>0.944757</td>\n",
       "      <td>0.782537</td>\n",
       "      <td>0.889469</td>\n",
       "      <td>0.916187</td>\n",
       "      <td>0.851685</td>\n",
       "      <td>0.910680</td>\n",
       "      <td>0.923992</td>\n",
       "      <td>0.986000</td>\n",
       "      <td>0.370997</td>\n",
       "      <td>0.375315</td>\n",
       "      <td>0.757616</td>\n",
       "      <td>0.797698</td>\n",
       "      <td>0.619422</td>\n",
       "      <td>0.560731</td>\n",
       "      <td>0.305792</td>\n",
       "      <td>0.444103</td>\n",
       "      <td>0.578370</td>\n",
       "      <td>0.730623</td>\n",
       "      <td>0.517234</td>\n",
       "      <td>1</td>\n",
       "      <td>329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>005ee057d917de0d9fea9964630d19df43e08f4377f67c14e85168f4b3df34a4</th>\n",
       "      <td>0.486090</td>\n",
       "      <td>0.584725</td>\n",
       "      <td>0.793851</td>\n",
       "      <td>0.596131</td>\n",
       "      <td>0.863285</td>\n",
       "      <td>0.900613</td>\n",
       "      <td>0.707706</td>\n",
       "      <td>0.985649</td>\n",
       "      <td>0.891718</td>\n",
       "      <td>0.533259</td>\n",
       "      <td>0.894479</td>\n",
       "      <td>0.342814</td>\n",
       "      <td>0.945802</td>\n",
       "      <td>0.640318</td>\n",
       "      <td>0.913347</td>\n",
       "      <td>0.959335</td>\n",
       "      <td>0.992768</td>\n",
       "      <td>0.939981</td>\n",
       "      <td>0.951848</td>\n",
       "      <td>0.937967</td>\n",
       "      <td>0.989068</td>\n",
       "      <td>0.671480</td>\n",
       "      <td>0.874622</td>\n",
       "      <td>0.884257</td>\n",
       "      <td>0.989481</td>\n",
       "      <td>0.977103</td>\n",
       "      <td>0.965211</td>\n",
       "      <td>0.830006</td>\n",
       "      <td>0.995495</td>\n",
       "      <td>0.856457</td>\n",
       "      <td>0.731042</td>\n",
       "      <td>0.710099</td>\n",
       "      <td>0.401789</td>\n",
       "      <td>0.926070</td>\n",
       "      <td>0.948480</td>\n",
       "      <td>0.804498</td>\n",
       "      <td>0.886618</td>\n",
       "      <td>0.878309</td>\n",
       "      <td>0.910309</td>\n",
       "      <td>0.970322</td>\n",
       "      <td>0.789138</td>\n",
       "      <td>0.963120</td>\n",
       "      <td>0.870599</td>\n",
       "      <td>0.944876</td>\n",
       "      <td>0.990914</td>\n",
       "      <td>1</td>\n",
       "      <td>143.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00605ffabc4ff701bc81f82e2e7a446ca0f3dc97b08cd5b267140cfaff4d83ae</th>\n",
       "      <td>0.413913</td>\n",
       "      <td>0.617890</td>\n",
       "      <td>0.309687</td>\n",
       "      <td>0.529493</td>\n",
       "      <td>0.284613</td>\n",
       "      <td>0.659095</td>\n",
       "      <td>0.728172</td>\n",
       "      <td>0.939295</td>\n",
       "      <td>0.448593</td>\n",
       "      <td>0.317670</td>\n",
       "      <td>0.313910</td>\n",
       "      <td>0.246137</td>\n",
       "      <td>0.844136</td>\n",
       "      <td>0.940742</td>\n",
       "      <td>0.813230</td>\n",
       "      <td>0.487679</td>\n",
       "      <td>0.596709</td>\n",
       "      <td>0.474391</td>\n",
       "      <td>0.270629</td>\n",
       "      <td>0.662611</td>\n",
       "      <td>0.743733</td>\n",
       "      <td>0.930633</td>\n",
       "      <td>0.933388</td>\n",
       "      <td>0.614147</td>\n",
       "      <td>0.952221</td>\n",
       "      <td>0.944211</td>\n",
       "      <td>0.956925</td>\n",
       "      <td>0.956453</td>\n",
       "      <td>0.948823</td>\n",
       "      <td>0.988689</td>\n",
       "      <td>0.984003</td>\n",
       "      <td>0.992484</td>\n",
       "      <td>0.983547</td>\n",
       "      <td>0.991279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>99.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0067505eb790ff1074f3594e9d21f159e42815eb1c2f673cd19e44ae48623e8f</th>\n",
       "      <td>0.411835</td>\n",
       "      <td>0.688843</td>\n",
       "      <td>0.488133</td>\n",
       "      <td>0.430451</td>\n",
       "      <td>0.607323</td>\n",
       "      <td>0.955554</td>\n",
       "      <td>0.558092</td>\n",
       "      <td>0.986310</td>\n",
       "      <td>0.895077</td>\n",
       "      <td>0.504149</td>\n",
       "      <td>0.779935</td>\n",
       "      <td>0.412970</td>\n",
       "      <td>0.849054</td>\n",
       "      <td>0.860607</td>\n",
       "      <td>0.939733</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>0.140440</td>\n",
       "      <td>0.111801</td>\n",
       "      <td>0.201712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>69.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>006ac63024244a6477a939e96b51051e43d8b98296146a54d6d92e4288687c80</th>\n",
       "      <td>0.569528</td>\n",
       "      <td>0.781655</td>\n",
       "      <td>0.743160</td>\n",
       "      <td>0.455927</td>\n",
       "      <td>0.747769</td>\n",
       "      <td>0.899116</td>\n",
       "      <td>0.713085</td>\n",
       "      <td>0.871311</td>\n",
       "      <td>0.693991</td>\n",
       "      <td>0.366794</td>\n",
       "      <td>0.885958</td>\n",
       "      <td>0.779268</td>\n",
       "      <td>0.850693</td>\n",
       "      <td>0.946365</td>\n",
       "      <td>0.940444</td>\n",
       "      <td>0.964224</td>\n",
       "      <td>0.928620</td>\n",
       "      <td>0.869872</td>\n",
       "      <td>0.860076</td>\n",
       "      <td>0.966617</td>\n",
       "      <td>0.949815</td>\n",
       "      <td>0.959236</td>\n",
       "      <td>0.989740</td>\n",
       "      <td>0.985181</td>\n",
       "      <td>0.994591</td>\n",
       "      <td>0.831012</td>\n",
       "      <td>0.990811</td>\n",
       "      <td>0.973000</td>\n",
       "      <td>0.990271</td>\n",
       "      <td>0.938358</td>\n",
       "      <td>0.924808</td>\n",
       "      <td>0.987734</td>\n",
       "      <td>0.975576</td>\n",
       "      <td>0.981846</td>\n",
       "      <td>0.984233</td>\n",
       "      <td>0.949742</td>\n",
       "      <td>0.906456</td>\n",
       "      <td>0.971672</td>\n",
       "      <td>0.978805</td>\n",
       "      <td>0.823007</td>\n",
       "      <td>0.868244</td>\n",
       "      <td>0.911800</td>\n",
       "      <td>0.896956</td>\n",
       "      <td>0.942664</td>\n",
       "      <td>0.913571</td>\n",
       "      <td>1</td>\n",
       "      <td>219.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          12        22  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.478540  0.598060   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.526600  0.614885   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.563810  0.688602   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.654678  0.666470   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.410807  0.697154   \n",
       "005e3a2f3a37e7afcc8050a73dfba1ef61394aa96202bba...  0.405662  0.552058   \n",
       "005ee057d917de0d9fea9964630d19df43e08f4377f67c1...  0.486090  0.584725   \n",
       "00605ffabc4ff701bc81f82e2e7a446ca0f3dc97b08cd5b...  0.413913  0.617890   \n",
       "0067505eb790ff1074f3594e9d21f159e42815eb1c2f673...  0.411835  0.688843   \n",
       "006ac63024244a6477a939e96b51051e43d8b98296146a5...  0.569528  0.781655   \n",
       "\n",
       "                                                          24        32  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.066167  0.087926   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.296109  0.258713   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.437219  0.520770   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.551776  0.549546   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.627104  0.425629   \n",
       "005e3a2f3a37e7afcc8050a73dfba1ef61394aa96202bba...  0.256317  0.550325   \n",
       "005ee057d917de0d9fea9964630d19df43e08f4377f67c1...  0.793851  0.596131   \n",
       "00605ffabc4ff701bc81f82e2e7a446ca0f3dc97b08cd5b...  0.309687  0.529493   \n",
       "0067505eb790ff1074f3594e9d21f159e42815eb1c2f673...  0.488133  0.430451   \n",
       "006ac63024244a6477a939e96b51051e43d8b98296146a5...  0.743160  0.455927   \n",
       "\n",
       "                                                          34        36  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.067840  0.161989   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.244836  0.324150   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.511848  0.659244   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.796762  0.727291   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.574905  0.544934   \n",
       "005e3a2f3a37e7afcc8050a73dfba1ef61394aa96202bba...  0.355961  0.707999   \n",
       "005ee057d917de0d9fea9964630d19df43e08f4377f67c1...  0.863285  0.900613   \n",
       "00605ffabc4ff701bc81f82e2e7a446ca0f3dc97b08cd5b...  0.284613  0.659095   \n",
       "0067505eb790ff1074f3594e9d21f159e42815eb1c2f673...  0.607323  0.955554   \n",
       "006ac63024244a6477a939e96b51051e43d8b98296146a5...  0.747769  0.899116   \n",
       "\n",
       "                                                          42        44  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.199271  0.309149   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.389767  0.860500   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.486146  0.919635   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.752763  0.971220   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.818765  0.970679   \n",
       "005e3a2f3a37e7afcc8050a73dfba1ef61394aa96202bba...  0.559632  0.751667   \n",
       "005ee057d917de0d9fea9964630d19df43e08f4377f67c1...  0.707706  0.985649   \n",
       "00605ffabc4ff701bc81f82e2e7a446ca0f3dc97b08cd5b...  0.728172  0.939295   \n",
       "0067505eb790ff1074f3594e9d21f159e42815eb1c2f673...  0.558092  0.986310   \n",
       "006ac63024244a6477a939e96b51051e43d8b98296146a5...  0.713085  0.871311   \n",
       "\n",
       "                                                          46        48  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.092753  0.019592   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.353952  0.262166   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.602856  0.554702   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.788836  0.756230   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.708364  0.841827   \n",
       "005e3a2f3a37e7afcc8050a73dfba1ef61394aa96202bba...  0.318067  0.184898   \n",
       "005ee057d917de0d9fea9964630d19df43e08f4377f67c1...  0.891718  0.533259   \n",
       "00605ffabc4ff701bc81f82e2e7a446ca0f3dc97b08cd5b...  0.448593  0.317670   \n",
       "0067505eb790ff1074f3594e9d21f159e42815eb1c2f673...  0.895077  0.504149   \n",
       "006ac63024244a6477a939e96b51051e43d8b98296146a5...  0.693991  0.366794   \n",
       "\n",
       "                                                          52        54  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.124007  0.095017   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.789966  0.715670   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.877253  0.956855   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.882442  0.978145   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.884527  0.956108   \n",
       "005e3a2f3a37e7afcc8050a73dfba1ef61394aa96202bba...  0.236122  0.281500   \n",
       "005ee057d917de0d9fea9964630d19df43e08f4377f67c1...  0.894479  0.342814   \n",
       "00605ffabc4ff701bc81f82e2e7a446ca0f3dc97b08cd5b...  0.313910  0.246137   \n",
       "0067505eb790ff1074f3594e9d21f159e42815eb1c2f673...  0.779935  0.412970   \n",
       "006ac63024244a6477a939e96b51051e43d8b98296146a5...  0.885958  0.779268   \n",
       "\n",
       "                                                          56        58  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.123710  0.046480   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.732399  0.711719   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.955341  0.874749   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.980208  0.977553   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.982398  0.974754   \n",
       "005e3a2f3a37e7afcc8050a73dfba1ef61394aa96202bba...  0.652278  0.447956   \n",
       "005ee057d917de0d9fea9964630d19df43e08f4377f67c1...  0.945802  0.640318   \n",
       "00605ffabc4ff701bc81f82e2e7a446ca0f3dc97b08cd5b...  0.844136  0.940742   \n",
       "0067505eb790ff1074f3594e9d21f159e42815eb1c2f673...  0.849054  0.860607   \n",
       "006ac63024244a6477a939e96b51051e43d8b98296146a5...  0.850693  0.946365   \n",
       "\n",
       "                                                          60        62  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.131178  0.135398   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.167221  0.724467   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.946754  0.941794   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.982317  0.946826   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.945515  0.958854   \n",
       "005e3a2f3a37e7afcc8050a73dfba1ef61394aa96202bba...  0.156842  0.614004   \n",
       "005ee057d917de0d9fea9964630d19df43e08f4377f67c1...  0.913347  0.959335   \n",
       "00605ffabc4ff701bc81f82e2e7a446ca0f3dc97b08cd5b...  0.813230  0.487679   \n",
       "0067505eb790ff1074f3594e9d21f159e42815eb1c2f673...  0.939733  0.866047   \n",
       "006ac63024244a6477a939e96b51051e43d8b98296146a5...  0.940444  0.964224   \n",
       "\n",
       "                                                          64        66  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.213251  0.028176   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.924575  0.885020   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.937908  0.967760   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.943856  0.947675   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.988558  0.954283   \n",
       "005e3a2f3a37e7afcc8050a73dfba1ef61394aa96202bba...  0.763232  0.949061   \n",
       "005ee057d917de0d9fea9964630d19df43e08f4377f67c1...  0.992768  0.939981   \n",
       "00605ffabc4ff701bc81f82e2e7a446ca0f3dc97b08cd5b...  0.596709  0.474391   \n",
       "0067505eb790ff1074f3594e9d21f159e42815eb1c2f673...  0.140440  0.111801   \n",
       "006ac63024244a6477a939e96b51051e43d8b98296146a5...  0.928620  0.869872   \n",
       "\n",
       "                                                          68        70  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.034467  0.026408   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.830663  0.863784   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.905928  0.871522   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.957861  0.947037   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.937327  0.977011   \n",
       "005e3a2f3a37e7afcc8050a73dfba1ef61394aa96202bba...  0.899879  0.820812   \n",
       "005ee057d917de0d9fea9964630d19df43e08f4377f67c1...  0.951848  0.937967   \n",
       "00605ffabc4ff701bc81f82e2e7a446ca0f3dc97b08cd5b...  0.270629  0.662611   \n",
       "0067505eb790ff1074f3594e9d21f159e42815eb1c2f673...  0.201712       NaN   \n",
       "006ac63024244a6477a939e96b51051e43d8b98296146a5...  0.860076  0.966617   \n",
       "\n",
       "                                                          72        74  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.062414  0.220668   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.752941  0.968490   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.915761  0.929437   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.859779  0.980214   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.918579  0.992553   \n",
       "005e3a2f3a37e7afcc8050a73dfba1ef61394aa96202bba...  0.694565  0.339294   \n",
       "005ee057d917de0d9fea9964630d19df43e08f4377f67c1...  0.989068  0.671480   \n",
       "00605ffabc4ff701bc81f82e2e7a446ca0f3dc97b08cd5b...  0.743733  0.930633   \n",
       "0067505eb790ff1074f3594e9d21f159e42815eb1c2f673...       NaN       NaN   \n",
       "006ac63024244a6477a939e96b51051e43d8b98296146a5...  0.949815  0.959236   \n",
       "\n",
       "                                                          76        78  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.020097  0.026782   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.956954  0.362114   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.863017  0.887714   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.978365  0.986316   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.988978  0.705655   \n",
       "005e3a2f3a37e7afcc8050a73dfba1ef61394aa96202bba...  0.821932  0.950007   \n",
       "005ee057d917de0d9fea9964630d19df43e08f4377f67c1...  0.874622  0.884257   \n",
       "00605ffabc4ff701bc81f82e2e7a446ca0f3dc97b08cd5b...  0.933388  0.614147   \n",
       "0067505eb790ff1074f3594e9d21f159e42815eb1c2f673...       NaN       NaN   \n",
       "006ac63024244a6477a939e96b51051e43d8b98296146a5...  0.989740  0.985181   \n",
       "\n",
       "                                                          80        82  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.010254  0.040333   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.848653  0.661463   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.950233  0.835233   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.984399  0.986981   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.989564  0.928219   \n",
       "005e3a2f3a37e7afcc8050a73dfba1ef61394aa96202bba...  0.612075  0.877753   \n",
       "005ee057d917de0d9fea9964630d19df43e08f4377f67c1...  0.989481  0.977103   \n",
       "00605ffabc4ff701bc81f82e2e7a446ca0f3dc97b08cd5b...  0.952221  0.944211   \n",
       "0067505eb790ff1074f3594e9d21f159e42815eb1c2f673...       NaN       NaN   \n",
       "006ac63024244a6477a939e96b51051e43d8b98296146a5...  0.994591  0.831012   \n",
       "\n",
       "                                                          84        86  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.096306  0.387979   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.595192  0.801989   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.967029  0.404402   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.981158  0.977469   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.969705  0.983640   \n",
       "005e3a2f3a37e7afcc8050a73dfba1ef61394aa96202bba...  0.944757  0.782537   \n",
       "005ee057d917de0d9fea9964630d19df43e08f4377f67c1...  0.965211  0.830006   \n",
       "00605ffabc4ff701bc81f82e2e7a446ca0f3dc97b08cd5b...  0.956925  0.956453   \n",
       "0067505eb790ff1074f3594e9d21f159e42815eb1c2f673...       NaN       NaN   \n",
       "006ac63024244a6477a939e96b51051e43d8b98296146a5...  0.990811  0.973000   \n",
       "\n",
       "                                                          88        90  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.212772  0.072036   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.188171  0.303732   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.650530  0.811946   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.997820  0.983914   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.937284  0.925274   \n",
       "005e3a2f3a37e7afcc8050a73dfba1ef61394aa96202bba...  0.889469  0.916187   \n",
       "005ee057d917de0d9fea9964630d19df43e08f4377f67c1...  0.995495  0.856457   \n",
       "00605ffabc4ff701bc81f82e2e7a446ca0f3dc97b08cd5b...  0.948823  0.988689   \n",
       "0067505eb790ff1074f3594e9d21f159e42815eb1c2f673...       NaN       NaN   \n",
       "006ac63024244a6477a939e96b51051e43d8b98296146a5...  0.990271  0.938358   \n",
       "\n",
       "                                                          92        94  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.557166  0.389631   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.453194  0.803219   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.937773  0.903472   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...  0.961692       NaN   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.998654  0.977158   \n",
       "005e3a2f3a37e7afcc8050a73dfba1ef61394aa96202bba...  0.851685  0.910680   \n",
       "005ee057d917de0d9fea9964630d19df43e08f4377f67c1...  0.731042  0.710099   \n",
       "00605ffabc4ff701bc81f82e2e7a446ca0f3dc97b08cd5b...  0.984003  0.992484   \n",
       "0067505eb790ff1074f3594e9d21f159e42815eb1c2f673...       NaN       NaN   \n",
       "006ac63024244a6477a939e96b51051e43d8b98296146a5...  0.924808  0.987734   \n",
       "\n",
       "                                                          96        98  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.818208  0.808688   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.428179  0.626452   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.731678  0.737742   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...       NaN       NaN   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.979737  0.987146   \n",
       "005e3a2f3a37e7afcc8050a73dfba1ef61394aa96202bba...  0.923992  0.986000   \n",
       "005ee057d917de0d9fea9964630d19df43e08f4377f67c1...  0.401789  0.926070   \n",
       "00605ffabc4ff701bc81f82e2e7a446ca0f3dc97b08cd5b...  0.983547  0.991279   \n",
       "0067505eb790ff1074f3594e9d21f159e42815eb1c2f673...       NaN       NaN   \n",
       "006ac63024244a6477a939e96b51051e43d8b98296146a5...  0.975576  0.981846   \n",
       "\n",
       "                                                         100       102  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.086759  0.067867   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.334280  0.122963   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.728694  0.713203   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...       NaN       NaN   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.945632  0.893628   \n",
       "005e3a2f3a37e7afcc8050a73dfba1ef61394aa96202bba...  0.370997  0.375315   \n",
       "005ee057d917de0d9fea9964630d19df43e08f4377f67c1...  0.948480  0.804498   \n",
       "00605ffabc4ff701bc81f82e2e7a446ca0f3dc97b08cd5b...       NaN       NaN   \n",
       "0067505eb790ff1074f3594e9d21f159e42815eb1c2f673...       NaN       NaN   \n",
       "006ac63024244a6477a939e96b51051e43d8b98296146a5...  0.984233  0.949742   \n",
       "\n",
       "                                                         104       106  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.404800  0.572054   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.786025  0.730558   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.843723  0.902666   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...       NaN       NaN   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.953157  0.923174   \n",
       "005e3a2f3a37e7afcc8050a73dfba1ef61394aa96202bba...  0.757616  0.797698   \n",
       "005ee057d917de0d9fea9964630d19df43e08f4377f67c1...  0.886618  0.878309   \n",
       "00605ffabc4ff701bc81f82e2e7a446ca0f3dc97b08cd5b...       NaN       NaN   \n",
       "0067505eb790ff1074f3594e9d21f159e42815eb1c2f673...       NaN       NaN   \n",
       "006ac63024244a6477a939e96b51051e43d8b98296146a5...  0.906456  0.971672   \n",
       "\n",
       "                                                         108       110  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.313721  0.710828   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.256690  0.126523   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.827290  0.591851   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...       NaN       NaN   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.951265  0.973543   \n",
       "005e3a2f3a37e7afcc8050a73dfba1ef61394aa96202bba...  0.619422  0.560731   \n",
       "005ee057d917de0d9fea9964630d19df43e08f4377f67c1...  0.910309  0.970322   \n",
       "00605ffabc4ff701bc81f82e2e7a446ca0f3dc97b08cd5b...       NaN       NaN   \n",
       "0067505eb790ff1074f3594e9d21f159e42815eb1c2f673...       NaN       NaN   \n",
       "006ac63024244a6477a939e96b51051e43d8b98296146a5...  0.978805  0.823007   \n",
       "\n",
       "                                                         112       114  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.135832  0.212864   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.455722  0.098226   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.614171  0.672580   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...       NaN       NaN   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.981940  0.958897   \n",
       "005e3a2f3a37e7afcc8050a73dfba1ef61394aa96202bba...  0.305792  0.444103   \n",
       "005ee057d917de0d9fea9964630d19df43e08f4377f67c1...  0.789138  0.963120   \n",
       "00605ffabc4ff701bc81f82e2e7a446ca0f3dc97b08cd5b...       NaN       NaN   \n",
       "0067505eb790ff1074f3594e9d21f159e42815eb1c2f673...       NaN       NaN   \n",
       "006ac63024244a6477a939e96b51051e43d8b98296146a5...  0.868244  0.911800   \n",
       "\n",
       "                                                         116       118  \\\n",
       "filehash                                                                 \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.640768  0.152474   \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.349144  0.397491   \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.689227  0.713630   \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...       NaN       NaN   \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.984683  0.965030   \n",
       "005e3a2f3a37e7afcc8050a73dfba1ef61394aa96202bba...  0.578370  0.730623   \n",
       "005ee057d917de0d9fea9964630d19df43e08f4377f67c1...  0.870599  0.944876   \n",
       "00605ffabc4ff701bc81f82e2e7a446ca0f3dc97b08cd5b...       NaN       NaN   \n",
       "0067505eb790ff1074f3594e9d21f159e42815eb1c2f673...       NaN       NaN   \n",
       "006ac63024244a6477a939e96b51051e43d8b98296146a5...  0.896956  0.942664   \n",
       "\n",
       "                                                         120  winner  length  \n",
       "filehash                                                                      \n",
       "0016ddd5b36473f259ba8630c6c0047540a6858071737e8...  0.201989       0   161.2  \n",
       "00283dcee1b0bec45ff654a0df06248d9f69a5c3a66e782...  0.279488       0   178.2  \n",
       "0033334e86cb352b0131027e58effa23adb23cf1cdd90d5...  0.941513       1   214.6  \n",
       "0055f4541fe30a72e964fc168db7abef35822d27e4cdce8...       NaN       1    94.2  \n",
       "005ac860a39ec7ae855a22b68f13ea17c1d7006bafe381e...  0.996227       1   126.4  \n",
       "005e3a2f3a37e7afcc8050a73dfba1ef61394aa96202bba...  0.517234       1   329.0  \n",
       "005ee057d917de0d9fea9964630d19df43e08f4377f67c1...  0.990914       1   143.4  \n",
       "00605ffabc4ff701bc81f82e2e7a446ca0f3dc97b08cd5b...       NaN       1    99.4  \n",
       "0067505eb790ff1074f3594e9d21f159e42815eb1c2f673...       NaN       0    69.2  \n",
       "006ac63024244a6477a939e96b51051e43d8b98296146a5...  0.913571       1   219.8  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loop through each col in prediction results and get a dict of index to sum\n",
    "prob_index_dict = {}\n",
    "for col in prediction_results.columns:\n",
    "    # calculate the row at which the window ends\n",
    "    end_frame = int(col.split('_')[0]) + int(col.split('_')[1])\n",
    "    \n",
    "    # if the end frame is not in the dict, add it\n",
    "    if end_frame not in prob_index_dict.keys():\n",
    "        prob_index_dict[end_frame] = [col]\n",
    "    else:\n",
    "        prob_index_dict[end_frame].append(col)\n",
    "\n",
    "\n",
    "agg_predictions = pd.DataFrame()\n",
    "# loop through each key in the dict and get the mean of the values\n",
    "for end_frame in prob_index_dict.keys():\n",
    "    # calculate the row-wise mean of the values in these colums and add to the dataframe\n",
    "    agg_prob = prediction_results.loc[:, prob_index_dict[end_frame]].mean(axis=1)\n",
    "    \n",
    "    # add the mean as a column to the dataframe\n",
    "    agg_predictions[end_frame] = agg_prob\n",
    "\n",
    "# sort columns in ascending order\n",
    "agg_predictions = agg_predictions.reindex(\n",
    "    sorted(agg_predictions.columns),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# append game_winner to the dataframe\n",
    "agg_predictions['winner'] = pd.DataFrame().from_dict(labels, orient='index')\n",
    "\n",
    "# append game length to the dataframe\n",
    "agg_predictions['length'] = spawningtool_df.set_index('filehash')['game_length']/5\n",
    "\n",
    "agg_predictions.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data to csv\n",
    "agg_predictions.to_csv('data/agg_predictions.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filehash\n",
       "9384fda8c370ea7d130ac20244f7d0fda9a9b8340044452d2692b739ac9cc1e1     80.4\n",
       "f9864054498acf297aacf2be80896ba131716a341983de6714499ac77a0695ec     74.2\n",
       "178a82fa5045e82a3920688274d7a524595f0ef6dc91ae42a4cb9c9711fc5998     74.2\n",
       "99ba80721116d18f965c141581baa878abf02526f48bc6e937c2e3f1c89054be    360.6\n",
       "b9e96a1dabcc0de0cfd89e8f0d02b5b8e064ec3f3c07c1272022d6651cd24dcb    100.4\n",
       "                                                                    ...  \n",
       "86edadabea6cede88a70ed9102e0d45cdea7850d23ade8d6883f03e0fd7439e2    160.8\n",
       "42930fdc21561395bcefc960b2d5525f7b6adf11dc0eab635a034ae569a85167     76.2\n",
       "8d1c2a7a406cdedfdd8db8ae24968b16edfde4c1a38230c32c3ecfff4b2b9b20    254.4\n",
       "d6430bacdb3bc5a22e09d445655486cb06cf7e9d23b4799de8001f88b9cec84b    191.4\n",
       "b64731a1f706d4fa6b79778884209d77dc3cfe40308f6df7668060508a6ce697    122.6\n",
       "Name: game_length, Length: 36812, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spawningtool_df.set_index('filehash')['game_length']/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 ['0_12']\n",
      "22 ['10_12']\n",
      "32 ['20_12']\n",
      "42 ['30_12']\n",
      "52 ['40_12']\n",
      "62 ['50_12']\n",
      "72 ['60_12', '0_72']\n",
      "82 ['70_12', '10_72']\n",
      "92 ['80_12', '20_72']\n",
      "102 ['90_12', '30_72']\n",
      "112 ['100_12', '40_72']\n",
      "24 ['0_24']\n",
      "34 ['10_24']\n",
      "44 ['20_24']\n",
      "54 ['30_24']\n",
      "64 ['40_24']\n",
      "74 ['50_24']\n",
      "84 ['60_24', '0_84']\n",
      "94 ['70_24', '10_84']\n",
      "104 ['80_24', '20_84']\n",
      "114 ['90_24', '30_84']\n",
      "36 ['0_36']\n",
      "46 ['10_36']\n",
      "56 ['20_36']\n",
      "66 ['30_36']\n",
      "76 ['40_36']\n",
      "86 ['50_36']\n",
      "96 ['60_36', '0_96']\n",
      "106 ['70_36', '10_96']\n",
      "116 ['80_36', '20_96']\n",
      "48 ['0_48']\n",
      "58 ['10_48']\n",
      "68 ['20_48']\n",
      "78 ['30_48']\n",
      "88 ['40_48']\n",
      "98 ['50_48']\n",
      "108 ['60_48', '0_108']\n",
      "118 ['70_48', '10_108']\n",
      "60 ['0_60']\n",
      "70 ['10_60']\n",
      "80 ['20_60']\n",
      "90 ['30_60']\n",
      "100 ['40_60']\n",
      "110 ['50_60']\n",
      "120 ['60_60', '0_120']\n"
     ]
    }
   ],
   "source": [
    "for key, value in prob_index_dict.items():\n",
    "    print(key, value)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e547aa29629eb5c25aeeb45870ab448aed1803ed873d9ecef66cb983aa54d8de"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tflow2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
